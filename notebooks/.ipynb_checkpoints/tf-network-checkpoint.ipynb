{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "#Imports for visualization\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DisplayArray(a, fmt='jpeg', rng=[0,1]):\n",
    "    \"\"\"Display an array as a picture.\"\"\"\n",
    "    a = (a - rng[0])/float(rng[1] - rng[0])*255\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('summaries_dir', '/tmp/tensorflow_logs', 'Summaries directory')\n",
    "flags.DEFINE_string('data_dir', '/tmp/data', 'Directory for storing data')\n",
    "\n",
    "DEVICE = '/gpu:0'\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "dtVal = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_float(shape, name):\n",
    "#     return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
    "    return tf.Variable(tf.zeros(shape), name=name)\n",
    "\n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.scalar_summary('sttdev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    dt = tf.placeholder(tf.float32, shape=(), name='dt')\n",
    "    tauv = tf.placeholder(tf.float32, shape=(), name='tauv')\n",
    "\n",
    "    scaling = 1 / (1/(2*2/dtVal))**0.5 * 70\n",
    "\n",
    "    # Create variables for simulation state\n",
    "    u = init_float([N,1], 'u')\n",
    "    v = init_float([N,1], 'v')\n",
    "    t = tf.Variable(0, dtype='float32')\n",
    "    ind = tf.Variable(0, dtype='float32')\n",
    "    \n",
    "    LowSp = init_float([N,1], 'bursting')\n",
    "    vv = init_float([N,1], 'spiking')\n",
    "    \n",
    "    vmean = tf.Variable(0, dtype='float32')\n",
    "    umean = tf.Variable(0, dtype='float32')\n",
    "    vvmean = tf.Variable(0, dtype='float32')\n",
    "    imean = tf.Variable(0, dtype='float32')\n",
    "    gammamean = tf.Variable(0, dtype='float32')\n",
    "    \n",
    "\n",
    "    # currents\n",
    "    iBack = init_float([N,1], 'iBack')\n",
    "    iEff = init_float([N,1], 'iEff')\n",
    "    iGap = init_float([N,1], 'iGap')\n",
    "    iChem = init_float([N,1], 'iChem')\n",
    "    \n",
    "    # synaptics connection\n",
    "    conn = np.zeros([N, N], dtype='float32')\n",
    "    sG = 10\n",
    "    nbInCluster = int(N/2)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            conn[i][j] = ((i<(nbInCluster + sG)) & (j<(nbInCluster + sG)) ) \\\n",
    "            or ((i>=(nbInCluster - sG)) & (j>=(nbInCluster - sG)) )\n",
    "    allowedConnections = tf.Variable(conn)\n",
    "    nbOfGaps = np.sum(conn)\n",
    "    \n",
    "    g0 = 7 /nbOfGaps**0.5\n",
    "    wGap_init = np.ones([N, N], dtype=np.float32)*g0\n",
    "    wII_init = np.ones([N, N], dtype=np.float32)*500/N/dtVal\n",
    "    \n",
    "    wGap = tf.Variable(wGap_init * conn)\n",
    "    WII = tf.Variable(wII_init)\n",
    "\n",
    "    FACT = 1\n",
    "    ratio = 15\n",
    "    A_LTD  = 1e-0*4.7e-6 * FACT * N\n",
    "    A_LTP = ratio * A_LTD\n",
    "    \n",
    "    TImean = 130.0\n",
    "    TImean_simul = tf.ones([N,1], dtype='float32')*TImean\n",
    "    TImean_init =  tf.concat(0,[tf.ones([int(N/2),1]), tf.zeros([N-int(N/2),1])]) * TImean\n",
    "    \n",
    "#     spikes = init_float([4000,N], \"spikes\")\n",
    "#     sim_index = tf.Variable(0) #tf.constant([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):   \n",
    "    with tf.name_scope('Currents'):\n",
    "        # Discretized PDE update rules\n",
    "        iChem_ = iChem + dt/5 * (-iChem + tf.matmul(WII,tf.to_float(vv)))\n",
    "\n",
    "        # current\n",
    "        iBack_ = iBack + dt/2 * (-iBack + tf.random_normal((N,1), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None))  \n",
    "        iEff_ = iBack_ * scaling + tf.select(tf.greater(tf.ones([N,1])*t,300), TImean_simul, TImean_init)\n",
    "        iGap_ = tf.matmul(wGap,v) - tf.mul(tf.reshape(tf.reduce_sum(wGap, 0), (N,1)),v)\n",
    "\n",
    "        I_ = iGap_ + iChem_ + iEff_\n",
    "    \n",
    "    # IZHIKEVICH\n",
    "    with tf.name_scope('Izhikevich'):\n",
    "        t_ = t + dt\n",
    "        ind_ = ind + 1\n",
    "        # voltage\n",
    "        v_ = v + dt / tauv * (tf.mul((v + 60), (v +50)) - 20 * u + 8 * I_)\n",
    "        # adaptation\n",
    "        u_ = u + dt * 0.044 * (v_ + 55 - u)\n",
    "        # spikes\n",
    "        vv_ = tf.to_float(tf.greater(v_,25.0))\n",
    "        # reset\n",
    "        v_ = tf.mul(vv_,-40.0) + tf.mul((1-vv_),v_)\n",
    "        u_ = u_ + tf.mul(vv_,(50.0))\n",
    "\n",
    "    # bursting\n",
    "    with tf.name_scope('bursting'):\n",
    "        LowSp_ = LowSp + dt/10.0*(vv_ * 10.0 / dt - LowSp)\n",
    "        p = tf.to_float(tf.greater(LowSp_,1.3))\n",
    "    \n",
    "    # plasticity\n",
    "    with tf.name_scope('plasticity'):\n",
    "        A = tf.matmul(p,tf.ones([1,N]))\n",
    "        dwLTD_ = A_LTD*(A+tf.transpose(A))\n",
    "\n",
    "        # dwLTP_ = A_LTP * tf.mul(tf.to_float(vv_),(g0 - wGap))\n",
    "\n",
    "        B = tf.matmul(vv_, tf.ones([1,N]))\n",
    "        dwLTP_ = A_LTP*(tf.mul(tf.ones([N,N]) - 1/g0 * wGap, B+tf.transpose(B)))\n",
    "        # dwLTD_ = A_LTD * p\n",
    "        dwGap_ = dt * (dwLTP_ - dwLTD_)\n",
    "        wGap_ = tf.mul(tf.clip_by_value(wGap+dwGap_, clip_value_min=0, clip_value_max=10**10), allowedConnections)\n",
    "\n",
    "\n",
    "\n",
    "    # monitoring\n",
    "    with tf.name_scope('Monitoring'):\n",
    "        vmean_ = tf.reduce_mean(v_)\n",
    "        umean_ = tf.reduce_mean(u_)\n",
    "        imean_ = tf.reduce_mean(I_)\n",
    "        vvmean_ = tf.reduce_sum(tf.to_float(vv_))\n",
    "        gammamean_ = tf.reduce_mean(wGap_)\n",
    "\n",
    "\n",
    "#     with tf.name_scope('Raster_Plot'):\n",
    "#         sim_index = tf.constant([0])\n",
    "#         spike_update = tf.scatter_update(spikes, sim_index, tf.transpose(vv_))\n",
    "    \n",
    "\n",
    "    # Operation to update the state\n",
    "    step = tf.group(\n",
    "        t.assign(t_),\n",
    "        v.assign(v_),\n",
    "        vv.assign(vv_),\n",
    "        u.assign(u_),\n",
    "        iBack.assign(iBack_),\n",
    "        iEff.assign(iChem_),\n",
    "        LowSp.assign(LowSp_),\n",
    "        wGap.assign(wGap_),\n",
    "        vmean.assign(vmean_),\n",
    "        umean.assign(umean_),\n",
    "        imean.assign(imean_),\n",
    "        vvmean.assign(vvmean_),\n",
    "#         gammamean.assign(gammamean_),\n",
    "        )\n",
    "\n",
    "with tf.name_scope('Summaries'):\n",
    "    variable_summaries(v_, 'Monitoring/v')\n",
    "    variable_summaries(u_, 'u')\n",
    "    variable_summaries(I_, 'I')\n",
    "    variable_summaries(vv_, 'vv')\n",
    "    variable_summaries(wGap_, 'gamma')\n",
    "    w_hist = tf.histogram_summary(\"weights\", wGap_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.88\n"
     ]
    }
   ],
   "source": [
    "# Initialize state to initial conditions\n",
    "merged = tf.merge_all_summaries()\n",
    "train_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + '/train', sess.graph)\n",
    "\n",
    "# sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "# with sess.as_default():\n",
    "if 1:\n",
    "    vm=[]\n",
    "    um=[]\n",
    "    vvm=[]\n",
    "    im=[]\n",
    "    gamma=[]\n",
    "    t0 = time.time()\n",
    "    for i in range(4000):\n",
    "        # Step simulation\n",
    "        sess.run([step], feed_dict={dt: dtVal, tauv: 15})\n",
    "#         feed = {dt: dtVal, tauv: 15,sim_index: tf.constant([i])}\n",
    "#         sess.run(spike_update, feed_dict=feed)\n",
    "        # Visualize every 50 steps\n",
    "        if i % 10 == 0:\n",
    "            pass\n",
    "            summary = sess.run(merged, feed_dict={dt: dtVal, tauv: 15})\n",
    "            train_writer.add_summary(summary, i)\n",
    "            clear_output(wait=True)\n",
    "#             DisplayArray(wGap.eval(), rng=[0, 2*g0])\n",
    "#             vm.append(vmean.eval())\n",
    "#             um.append(umean.eval())\n",
    "#             vvm.append(vvmean.eval())\n",
    "#             im.append(imean.eval())\n",
    "#             gamma.append(gammamean.eval())\n",
    "#         if i % 100 == 0:\n",
    "#             run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "#             run_metadata = tf.RunMetadata()\n",
    "#             train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "        \n",
    "print('%.2f'%(time.time()-t0))\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spikes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-529988c1097f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m plt.imshow(sp.transpose(), extent=extent, aspect=0.3*(extent[1] - extent[0]) / (\n\u001b[1;32m      5\u001b[0m             extent[3] - extent[2]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spikes' is not defined"
     ]
    }
   ],
   "source": [
    "sp =tf.convert_to_tensor(spikes).eval()\n",
    "plt.figure(figsize=(12,4))\n",
    "extent=[0,4000,0,300]\n",
    "plt.imshow(sp.transpose(), extent=extent, aspect=0.3*(extent[1] - extent[0]) / (\n",
    "            extent[3] - extent[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(vvm[-100:])\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(np.array(gamma)*N**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,2))\n",
    "ax0 = fig.add_subplot(141)\n",
    "ax1 = fig.add_subplot(142)\n",
    "ax2 = fig.add_subplot(143)\n",
    "ax3 = fig.add_subplot(144)\n",
    "\n",
    "ax0.plot(vm)\n",
    "\n",
    "ax1.plot(um)\n",
    "ax1.set_title('adaptation')\n",
    "\n",
    "ax2.plot(vvm)\n",
    "ax2.set_title('spiking')\n",
    "\n",
    "ax3.plot(im)\n",
    "ax3.set_title('current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
